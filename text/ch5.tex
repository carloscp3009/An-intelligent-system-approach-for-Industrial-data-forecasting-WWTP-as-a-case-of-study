This chapter presents the results of the proposed approaches implementation. Additional details of the models are given and their performance for training and testing data. 

\section{Variables Selection}
\label{s:results_data_selection}

The Pearson correlation is calculated to select the optimal input variables for the system. \autoref{t:correlation_table} summarizes the correlation values for the three target variables where \ac{COD}\textsubscript{D}, \ac{COD}\textsubscript{EQ}, and \ac{MLVSS} are one-day a head shifted variables.

\input{tables/correlation_table}

Variables that present a correlation higher than 0.2 are selected as inputs for the system. As a result, the input variables for each target variable are shown below:

\begin{itemize}
    \item \textbf{COD\textsubscript{D} :} D\_SS, BT\_C\_N, EQ\_N, BT\_C\_DO, ST\_COD, EQ\_COD, D\_COD\_ON.
    \item \textbf{COD\textsubscript{EQ} :} BT\_C\_MVLSS, D\_SS, EQ\_N, BT\_C\_N, OxT\_PH\_PM, BT\_N\_DO, Clari\_DO, ST\_COD, EQ\_COD.
    \item \textbf{MLVSS :} BT\_C\_MVLSS, D\_SS, EQ\_N, BT\_C\_N, OxT\_PH\_PM, BT\_C\_DO, Clari\_DO, ST\_COD, EQ\_COD.
\end{itemize}

It is necessary to standardize these variables to take them to similar level values. This step helps the model give the same level of relevance to each input variable no matter its magnitude value.

\begin{equation}
    X'_i = \frac{x_i - x_{mean}}{x_{std}}
\end{equation}

\begin{itemize}
    \item \begin{math}X'_i\end{math} is each standardized value.
    \item \begin{math}X_i\end{math} is each raw value.
    \item \begin{math}X_{mean}\end{math} is the mean value of the variable in the training dataset.
    \item \begin{math}X_{std}\end{math} is the standard deviation value of the variable in the training dataset.
\end{itemize}


\section{Approach 1 - Decomposition }
\label{s:resutls-approach1}
The first approach conducts the time series decomposition just as described in \autoref{ss:time-series-decomposition} for each target variable. It estimates the trend and seasonal components by applying auto-regression of its past values, a process supported in the auto-correlation study just as mentioned in \autoref{ss:autocorrelation}. The residual component is predicted by a \ac{FFNN} that receives the inputs presented in \autoref{s:results_data_selection} and includes the real residual value as an additional input feature. The \ac{FFNN} architecture and the approach prediction results are presented below.
All model hyper-parameters were tuned by a grid search between the following options:

\begin{itemize}
    \item Loss = [mse, mae]
    \item Optimizer = [SGD, adam]
    \item Activation = [linear, tanh, relu]
    \item Number of Layers = [1, 2]
    \item Number of Neurons per layer = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]
    \item Batch Normalization = [0, 1]
\end{itemize}

\subsection{COD Discharge}
\autoref{f:App1-codd-nn} shows the structure of the \ac{FFNN} used for \ac{COD}\textsubscript{D} residual prediction which hyper-parameters are presented below. \autoref{f:App1-codd} shows the prediction results of this approach where the orange line corresponds to model prediction over the training data, the red line to the model prediction over the testing samples. Finally, the blue one indicates the actual value the target variable takes.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\linewidth]{figures/Ch5/App1_CODeq.pdf}
\caption{Approach 1 - COD\textsubscript{D} Network}
\label{f:App1-codd-nn}
\end{figure}

\begin{figure}[hb!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-1.pdf}
\caption{Approach 1 - COD\textsubscript{D}}
\label{f:App1-codd}
\end{figure}

\begin{itemize}
    \item Loss = mse
    \item Optimizer = SGD
    \item Activation =  tanh
    \item Number of Layers = 2
    \item Number of Neurons per layer = [6, 24]
    \item Batch Normalization = 1
\end{itemize}

\subsection{COD Equalizer}
\autoref{f:App1-codeq-nn} shows the structure of the \ac{FFNN} used for \ac{COD}\textsubscript{EQ} residual prediction which hyper-parameters are presented below. \autoref{f:App1-codd} shows the prediction results of this approach.

\begin{itemize}
    \item Loss = mse
    \item Optimizer = SGD
    \item Activation =  Linear
    \item Number of Layers = 2
    \item Number of Neurons per layer = [10, 18]
    \item Batch Normalization = 1
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.4\linewidth]{figures/Ch5/App1_CODd.pdf}
\caption{Approach 1 - COD\textsubscript{EQ} Network}
\label{f:App1-codeq-nn}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-1.pdf}
\caption{Approach 1 - COD\textsubscript{EQ}}
\label{f:App1-codeq}
\end{figure}

\subsection{MLVSS}

\autoref{f:App1-MLVSS-nn} shows the structure of the \ac{FFNN} used for \ac{MLVSS} residual prediction which hyper-parameters are presented below. \autoref{f:App1-MLVSS} shows the prediction results of this approach.

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\linewidth]{figures/Ch5/App1_MLVSS.pdf}
\caption{Approach 1 - MLVSS Network}
\label{f:App1-MLVSS-nn}
\end{figure}

\begin{itemize}
    \item Loss = mse
    \item Optimizer = SGD
    \item Activation =  Relu
    \item Number of Layers = 2
    \item Number of Neurons per layer = [14, 22]
    \item Batch Normalization = 1
\end{itemize}
%------------------------------------------------
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MLVSS-approach1.pdf}
\caption{Approach 1 - MLVSS}
\label{f:App1-MLVSS}
\end{figure}





\section{Approach 2 - LSTM}
The \ac{LSTM} architecture for each target variable and the approach prediction results are presented below. The \ac{LSTM} network implemented takes until seven past days to predict one day ahead.
All model hyper-parameters were tuned by a grid search within the following options:

\begin{itemize}
    \item Loss = [mse, mae]
    \item Optimizer = [SGD, adam]
    \item Activation = [Relu, linear, tanh]
    \item Number of Layers = [1, 2]
    \item Length of the output vector = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]
    \item Batch Normalization = [0, 1]
    \item Dropout = [0, 1]
\end{itemize}

For Batch normalization and Dropout, zero means they are not included in the network.

\subsection{COD Discharge}
\autoref{f:App2-codd-nn} shows the structure of the \ac{LSTM} used for \ac{COD}\textsubscript{D} prediction which hyper-parameters are presented below. \autoref{f:App2-codd} shows the prediction results of this approach.

\begin{figure}[h]
\centering
 \includegraphics[width=0.4\linewidth]{figures/Ch5/App2_CODd.pdf}
\caption{Approach 2 - COD\textsubscript{D} LSTM Network}
\label{f:App2-codd-nn}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-2.pdf}
\caption{Approach 2 - COD\textsubscript{D}}
\label{f:App2-codd}
\end{figure}

\begin{itemize}
    \item Loss = mse
    \item Optimizer = SGD
    \item Activation =  Tanh
    \item Number of Layers = 2
    \item Length of the output vector = [4, 32]
    \item Batch Normalization = 0
    \item Dropout = 1
\end{itemize}

\subsection{COD Equalizer}
\autoref{f:App2-codeq-nn} shows the structure of the \ac{LSTM} used for \ac{COD}\textsubscript{EQ} prediction which hyper-parameters are presented below. \autoref{f:App2-codeq} shows the prediction results of this approach.

\begin{itemize}
    \item Loss = mse
    \item Optimizer = Adam
    \item Activation =  Tanh
    \item Number of Layers = 2
    \item Length of the output vector = [2, 18]
    \item Batch Normalization = 1
    \item Dropout = 0
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.4\linewidth]{figures/Ch5/App2_CODeq.pdf}
\caption{Approach 2 - COD\textsubscript{EQ} LSTM Network}
\label{f:App2-codeq-nn}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-2.pdf}
\caption{Approach 2 - COD\textsubscript{EQ}}
\label{f:App2-codeq}
\end{figure}

\subsection{MLVSS}
\autoref{f:App2-MLVSS-nn} shows the structure of the \ac{LSTM} used for \ac{MLVSS} prediction which hyper-parameters are presented below. \autoref{f:App2-MLVSS} shows the prediction results of this approach.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\linewidth]{figures/Ch5/App2_MLVSS.pdf}
\caption{Approach 2 - MLVSS LSTM Network}
\label{f:App2-MLVSS-nn}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MLVSS-approach2.pdf}
\caption{Approach 2 - MLVSS}
\label{f:App2-MLVSS}
\end{figure}

\begin{itemize}
    \item Loss = mse
    \item Optimizer = Adam
    \item Activation =  Linear
    \item Number of Layers = 2
    \item Length of the output vector = [4, 10]
    \item Batch Normalization = 1
    \item Dropout = 0
\end{itemize}

%-----------------------------------------------
\section{Approach 3 - SVR}
The \ac{SVR} approach uses a \ac{RBF} kernel. Model hyper-parameters were tuned by an empirical search within the following options:

\begin{itemize}
    \item Gamma = [0.0001 - 1]
    \item Epsilon = [0.001 - 10]
    \item C = [1 - 20]
\end{itemize}
%gamma of 0.001, epsilon equal to 0.2 and c value of 10.
\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-3.pdf}
\caption{Approach 3 - COD\textsubscript{D}}
\label{f:App3-codd}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-3.pdf}
\caption{Approach 3 - COD\textsubscript{EQ}}
\label{f:App3-codeq}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MLVSS-approach3.pdf}
\caption{Approach 3 - MLVSS}
\label{f:App3-MLVSS}
\end{figure}



This third model sometimes presents a shift prediction respect the expected value, nonetheless it achieves a good prediction. \autoref{f:App3-codd}, \autoref{f:App3-codeq}, and \autoref{f:App3-MLVSS} show the prediction results of this approach. 
\clearpage

%-----------------------------------------------
\section{Ensemble Approach 1 - Average}
The first ensemble approach makes an average of all three models presented before. \autoref{f:avg-codd}, \autoref{f:avg-codeq} and \autoref{f:avg-MLVSS} show the results of the average ensemble prediction for COD\textsubscript{D}, COD\textsubscript{EQ}, and MLVSS, respectively. 

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-avg.pdf}
\caption{Average Ensemble - COD\textsubscript{D}}
\label{f:avg-codd}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-avg.pdf}
\caption{Average Ensemble - COD\textsubscript{EQ}}
\label{f:avg-codeq}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MVLSS-E_avg.pdf}
\caption{Average Ensemble - MLVSS}
\label{f:avg-MLVSS}
\end{figure}

%-----------------------------------------------
\section{Ensemble Approach 2 - MLP Fusion}
The second ensemble approach fuses all three models output presented before using a \ac{MLP}, and uses the exogenous variables as information source to enhance the final prediction. \autoref{f:avg-codd}, \autoref{f:avg-codeq} and \autoref{f:avg-MLVSS} show the results of the \ac{MLP} fusion ensemble prediction for the target variables. 

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-ann.pdf}
\caption{MLP Ensemble - COD\textsubscript{D}}
\label{f:ann-codd}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-ann.pdf}
\caption{MLP Ensemble - COD\textsubscript{EQ}}
\label{f:ann-codeq}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MVLSS-E_ann.pdf}
\caption{MLP Ensemble - MLVSS}
\label{f:ann-MLVSS}
\end{figure}

%-----------------------------------------------
\section{Ensemble Approach 3 - Selection}
The last ensemble approach predicts which model will perform best based on the process conditions represented by the exogenous variables. This prediction allows selecting one of the single models as the most suitable one to carry out the prediction. \autoref{f:avg-codd}, \autoref{f:avg-codeq} and \autoref{f:avg-MLVSS} show the results of this ensemble approach prediction for the target variables. 

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODd-ann2.pdf}
\caption{MLP Ensemble - COD\textsubscript{D}}
\label{f:ann2-codd}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/CODeq-ann2.pdf}
\caption{MLP Ensemble - COD\textsubscript{EQ}}
\label{f:ann2-codeq}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figures/Ch5/MVLSS-E_ann2.pdf}
\caption{MLP Ensemble - MLVSS}
\label{f:ann2-MLVSS}
\end{figure}

\section{Discussion}
\label{s:Contribution-2-Summary}

This chapter presents the implementation and obtained results of three approaches predicting time series variables of the wastewater treatment process. Also, three different ensemble approaches are presented to enhance the intelligent system prediction performance.
\autoref{t:ResultsTrain} summarizes the \ac{MAPE} results achieved by the single models and the ensemble approaches during the training phase. It is worth mentioning that hyper-parameters tuning was made using this dataset. 
\input{tables/MapeTrain} 

\autoref{t:ResultsTest} shows the results over the testing dataset. It can be noted that the two best models are the Decomposition Approach and the Selection Ensemble. Because of the close similarity between their results, hypothesis testing is conducted to determine if there is a statistically meaningful difference in the models' performances. The null hypothesis is that the Mean of the \ac{MAPE} metric is equal for the Decomposition approach and Selection Ensemble. The alternative hypothesis dictates that there is evidence that both metrics are different.
\input{tables/MapeTest}

\newpage
\begin{align*}
H_{0}  & :\mu_{MAPE_{Decomposition App.}}=\mu_{MAPE_{Selection Ens.}}\\
H_{1}  & :\mu_{MAPE_{Decomposition App.}}\neq\mu_{MAPE_{Selection Ens.}}\\
\end{align*}

\autoref{t:Ttest} presents the T-statistic and the p-Value obtained from the testing. Setting a confidence interval of 95\% (\begin{math}\alpha = 0.05\end{math}) the p-Values of the testing dataset lead to not reject the null hypothesis. It is not possible to affirm that one model is better than the other in terms of \ac{MAPE} because they are not statistically different.
%The ensemble models offer a more robust prediction and present some improvements in \ac{MAPE}\%.
\input{tables/T-test}
%\input{tables/MAPEs} 

The Decomposition Approach and the Selection Ensemble present an equal performance. It is worth mentioning that the Decomposition Approach is much simpler than the Selection Ensemble, which is a bright spot for the first one. Despite that simplicity, the ensemble approach presents a compelling potential. The ensemble models tend to be more robust because their prediction depends on multiple models, not a single one. Different works in the literature support this statement \cite{Nourani2018, Nourani2021, Lu2020}.
